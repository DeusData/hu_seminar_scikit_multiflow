{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "otherwise-calculator",
   "metadata": {},
   "source": [
    "# Anomaly Detection\n",
    "\n",
    "In this notebook, you get a baseline for anomaly detection.\n",
    "\n",
    "<img src=\"https://box.hu-berlin.de/f/53a91798173c4dad9345/?dl=1\" width=800/>\n",
    "\n",
    "\n",
    "### Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "chubby-variation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import fnmatch\n",
    "import zipfile\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "import scipy as sp\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-investment",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "charged-increase",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_series(path, file, locations=None):   \n",
    "    print (path + \"/\"+ file)\n",
    "    data = pd.read_csv(path + \"/\"+ file, header=None)\n",
    "    data = np.array(data).flatten()\n",
    "    \n",
    "    # Extract file name\n",
    "    file_name = file.split('.')[0]\n",
    "    splits = file_name.split('_')\n",
    "    test_start = np.array(splits[-1])\n",
    "\n",
    "    # load the anomalies\n",
    "    if locations is None:\n",
    "        locations = pd.read_csv(\"phase_2/labels.csv\")\n",
    "        locations.set_index(\"Name\", inplace=True)\n",
    "\n",
    "    # Extract anomaly location\n",
    "    anomaly = [-1, -1]\n",
    "    if file_name in locations.index:\n",
    "        row = locations.loc[file_name]\n",
    "        anomaly = row[\"Pos\"]\n",
    "\n",
    "    return (file_name, int(test_start), data, anomaly)\n",
    "\n",
    "\n",
    "def find_dominant_window_sizes(ts, n_size=1):\n",
    "    fourier = np.absolute(np.fft.fft(ts))\n",
    "    freq = np.fft.fftfreq(ts.shape[0], 1)\n",
    "    coefs = []\n",
    "    window_sizes = []\n",
    "    for coef, freq in zip(fourier, freq):\n",
    "        if coef > 0 and freq > 0 and freq < 0.2:\n",
    "            window_size = 1.0 / freq\n",
    "            # avoid too large windows\n",
    "            if (window_size < 500) and (window_size > 10):\n",
    "                coefs.append(coef)\n",
    "                window_sizes.append(window_size)\n",
    "    coefs = np.array(coefs)\n",
    "    window_sizes = np.asarray(window_sizes, dtype=np.int64)\n",
    "    idx = np.argsort(coefs)[::-1]\n",
    "    \n",
    "    unique_window_sizes = set()\n",
    "    for window_size in window_sizes[idx]:\n",
    "        if len(unique_window_sizes) == n_size:\n",
    "            return np.array([w for w in unique_window_sizes])\n",
    "        unique_window_sizes.add(window_size)\n",
    "    return np.array(list(unique_window_sizes))\n",
    "\n",
    "\n",
    "def sliding_window(a, window):\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "    strides = a.strides + (a.strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n",
    "\n",
    "\n",
    "def visualize_with_anomaly_score(\n",
    "        data, score, test_start, \n",
    "        predicted, anomaly, name = None\n",
    "        ):\n",
    "    '''Input:\n",
    "       data: array with the raw data\n",
    "       test_start: the offset where the test data starts\n",
    "       predicted: The offset of your prediction.\n",
    "       anomaly: The offset of the anomaly. \n",
    "                      If -1 is passed, no anomaly is plottet.\n",
    "    '''\n",
    "    \n",
    "    anomaly_start = anomaly - 50    \n",
    "    anomaly_end = anomaly + 50\n",
    "    predicted_start = predicted - 50\n",
    "    predicted_end = predicted + 50\n",
    "    \n",
    "    fig, ax = plt.subplots(2,1, figsize=(20, 4), sharex=True)\n",
    "    sns.lineplot(x=np.arange(test_start, len(data)), y=data[test_start:], ax = ax[0], lw=0.5, label=\"Test\")\n",
    "    sns.lineplot(x=np.arange(0, test_start), y=data[:test_start], ax = ax[0], lw=0.5, label=\"Train\")\n",
    "        \n",
    "    if (anomaly_start > 0):\n",
    "        sns.lineplot(x=np.arange(anomaly_start, anomaly_end), \n",
    "                     y=data[anomaly_start:anomaly_end], ax = ax[0], label=\"Actual\")\n",
    "    \n",
    "    sns.lineplot(x=np.arange(len(score)), y=score, ax = ax[1], label=\"Anomaly Scores\")\n",
    "    sns.lineplot(x=np.arange(predicted_start, predicted_end), \n",
    "                 y=data[predicted_start:predicted_end], ax = ax[0], label=\"Predicted\")\n",
    "\n",
    "    if name is not None:\n",
    "        ax[0].set_title(name)\n",
    "        \n",
    "    sns.despine()\n",
    "\n",
    "    \n",
    "    #################\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-community",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "# Baseline: Anomaly Detection using Predictive Modelling\n",
    "\n",
    "You are now given an algorithm that computes an anomaly score for each time series:\n",
    "\n",
    "<img src=\"https://box.hu-berlin.de/f/2812ccfbcae24e318f9e/?dl=1\" width=800/>\n",
    "\n",
    "The score's maximum indicates where the anomaly is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "embedded-graphics",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase_2/001_Anomaly_5000.csv\n",
      "Current Score:  17.92225201072386\n",
      "phase_2/002_Anomaly_4375.csv\n",
      "Current Score:  17.966947349872246\n",
      "phase_2/003_Anomaly_4375.csv\n",
      "Current Score:  24.440047562146894\n",
      "phase_2/004_Anomaly_2500.csv\n",
      "Current Score:  19.83168406741663\n",
      "phase_2/005_Anomaly_4000.csv\n",
      "Current Score:  19.81899598210645\n",
      "phase_2/006_Anomaly_4000.csv\n",
      "Current Score:  19.473926380652646\n",
      "phase_2/007_Anomaly_4000.csv\n",
      "Current Score:  17.072377890763374\n",
      "phase_2/008_Anomaly_4000.csv\n",
      "Current Score:  15.179443816569844\n",
      "phase_2/009_Anomaly_4000.csv\n",
      "Current Score:  13.712781486194908\n",
      "phase_2/010_Anomaly_4000.csv\n",
      "Current Score:  12.481216161441488\n",
      "phase_2/011_Anomaly_3333.csv\n",
      "Current Score:  11.578245616342462\n",
      "phase_2/012_Anomaly_5000.csv\n",
      "Current Score:  11.466530152345571\n",
      "phase_2/013_Anomaly_5000.csv\n",
      "Current Score:  10.650167511715216\n",
      "phase_2/014_Anomaly_2666.csv\n",
      "Current Score:  9.944855316367388\n",
      "phase_2/015_Anomaly_250.csv\n",
      "Current Score:  9.405147097189664\n",
      "phase_2/016_Anomaly_1666.csv\n",
      "Current Score:  8.855012764185762\n",
      "phase_2/017_Anomaly_1666.csv\n",
      "Current Score:  8.364046563140688\n",
      "phase_2/018_Anomaly_2666.csv\n",
      "Current Score:  7.92568844354112\n",
      "phase_2/019_Anomaly_5000.csv\n",
      "Current Score:  7.5359080864047145\n",
      "phase_2/020_Anomaly_5000.csv\n",
      "Current Score:  7.214237316471547\n",
      "phase_2/021_Anomaly_5000.csv\n",
      "Current Score:  6.9342444068791735\n",
      "phase_2/022_Anomaly_4000.csv\n",
      "Current Score:  6.6573157585880445\n",
      "phase_2/023_Anomaly_5000.csv\n",
      "Current Score:  6.409792727221057\n",
      "phase_2/024_Anomaly_3200.csv\n",
      "Current Score:  6.171178795909993\n",
      "phase_2/025_Anomaly_2800.csv\n",
      "Current Score:  5.941380710353015\n",
      "phase_2/026_Anomaly_1700.csv\n",
      "Current Score:  5.805620760671997\n",
      "phase_2/027_Anomaly_1200.csv\n",
      "Current Score:  5.607630903573167\n",
      "phase_2/028_Anomaly_1600.csv\n",
      "Current Score:  5.460241332185587\n",
      "phase_2/029_Anomaly_2300.csv\n",
      "Current Score:  5.306381435927549\n",
      "phase_2/030_Anomaly_3000.csv\n",
      "Current Score:  5.145192480237106\n",
      "phase_2/031_Anomaly_2700.csv\n",
      "Current Score:  5.145192480237106\n",
      "phase_2/032_Anomaly_1000.csv\n",
      "Current Score:  5.080108340229696\n",
      "phase_2/033_Anomaly_1500.csv\n",
      "Current Score:  8.262024249111624\n",
      "phase_2/034_Anomaly_4200.csv\n",
      "Current Score:  8.262024249111624\n",
      "phase_2/035_Anomaly_2500.csv\n",
      "Current Score:  14.974374350927263\n",
      "phase_2/036_Anomaly_2000.csv\n",
      "Current Score:  14.974374350927263\n",
      "phase_2/037_Anomaly_3500.csv\n",
      "Current Score:  14.78353742567829\n",
      "phase_2/038_Anomaly_4500.csv\n",
      "Current Score:  15.523719928489497\n",
      "phase_2/039_Anomaly_8000.csv\n",
      "Current Score:  15.10477651659013\n",
      "phase_2/040_Anomaly_3500.csv\n",
      "Current Score:  15.158193328906586\n",
      "phase_2/041_Anomaly_3500.csv\n",
      "Current Score:  14.773791651073651\n",
      "phase_2/042_Anomaly_3500.csv\n",
      "Current Score:  14.410176026463475\n",
      "phase_2/043_Anomaly_2700.csv\n",
      "Current Score:  14.06035630795382\n",
      "phase_2/044_Anomaly_1666.csv\n",
      "Current Score:  13.734594928678213\n",
      "phase_2/045_Anomaly_3333.csv\n",
      "Current Score:  13.729481229926463\n",
      "phase_2/046_Anomaly_3666.csv\n",
      "Current Score:  13.729481229926463\n",
      "phase_2/047_Anomaly_3083.csv\n",
      "Current Score:  13.421968361269986\n",
      "phase_2/048_Anomaly_3900.csv\n",
      "Current Score:  13.126114111725832\n",
      "phase_2/049_Anomaly_3700.csv\n",
      "Current Score:  12.842935003993853\n",
      "phase_2/050_Anomaly_1300.csv\n",
      "Current Score:  13.430353682700916\n",
      "phase_2/051_Anomaly_3511.csv\n",
      "Current Score:  13.151148754108524\n",
      "phase_2/052_Anomaly_4000.csv\n",
      "Current Score:  12.882951957155742\n",
      "phase_2/053_Anomaly_1333.csv\n",
      "Current Score:  13.103458055627303\n",
      "phase_2/054_Anomaly_2526.csv\n",
      "Current Score:  13.103458055627303\n",
      "phase_2/055_Anomaly_5000.csv\n",
      "Current Score:  12.951861835256121\n",
      "phase_2/056_Anomaly_1578.csv\n",
      "Current Score:  13.596667411978455\n",
      "phase_2/057_Anomaly_3684.csv\n",
      "Current Score:  13.486317991906185\n",
      "phase_2/058_Anomaly_3000.csv\n",
      "Current Score:  13.237399005712186\n",
      "phase_2/059_Anomaly_2500.csv\n",
      "Current Score:  13.00698640346929\n",
      "phase_2/060_Anomaly_4000.csv\n",
      "Current Score:  12.81915400506847\n",
      "phase_2/061_Anomaly_4166.csv\n",
      "Current Score:  12.668255666697947\n",
      "phase_2/062_Anomaly_1666.csv\n",
      "Current Score:  12.668255666697947\n",
      "phase_2/063_Anomaly_2500.csv\n",
      "Current Score:  12.473975396582466\n",
      "phase_2/064_Anomaly_1666.csv\n",
      "Current Score:  12.270580630717106\n",
      "phase_2/065_Anomaly_1200.csv\n",
      "Current Score:  12.080356667824203\n",
      "phase_2/066_Anomaly_1666.csv\n",
      "Current Score:  11.884883964075124\n",
      "phase_2/067_Anomaly_5000.csv\n",
      "Current Score:  12.186188891649465\n",
      "phase_2/068_Anomaly_2000.csv\n",
      "Current Score:  12.098199498811491\n",
      "phase_2/069_Anomaly_3083.csv\n",
      "Current Score:  11.940709942963316\n",
      "phase_2/070_Anomaly_1500.csv\n",
      "Current Score:  12.702782249011044\n",
      "phase_2/071_Anomaly_4375.csv\n",
      "Current Score:  12.512660728643631\n",
      "phase_2/072_Anomaly_2500.csv\n",
      "Current Score:  13.552227529165911\n",
      "phase_2/073_Anomaly_4000.csv\n",
      "Current Score:  13.439617372003255\n",
      "phase_2/074_Anomaly_4000.csv\n",
      "Current Score:  13.259860071486736\n",
      "phase_2/075_Anomaly_4000.csv\n",
      "Current Score:  13.070433499036927\n",
      "phase_2/076_Anomaly_5000.csv\n",
      "Current Score:  13.299164644509451\n",
      "phase_2/077_Anomaly_2666.csv\n",
      "Current Score:  13.198033178822433\n",
      "phase_2/078_Anomaly_1666.csv\n",
      "Current Score:  13.094549696606677\n",
      "phase_2/079_Anomaly_2666.csv\n",
      "Current Score:  12.99891658063962\n",
      "phase_2/080_Anomaly_5000.csv\n",
      "Current Score:  12.857079174379237\n",
      "phase_2/081_Anomaly_4000.csv\n",
      "Current Score:  12.696280285721137\n",
      "phase_2/082_Anomaly_3200.csv\n",
      "Current Score:  12.533990931361123\n",
      "phase_2/083_Anomaly_1700.csv\n",
      "Current Score:  12.38072114209266\n",
      "phase_2/084_Anomaly_1600.csv\n",
      "Current Score:  12.248528469407942\n",
      "phase_2/085_Anomaly_3000.csv\n",
      "Current Score:  12.099290911159391\n",
      "phase_2/086_Anomaly_1000.csv\n",
      "Current Score:  11.974348398286079\n",
      "phase_2/087_Anomaly_1500.csv\n",
      "Current Score:  11.868631412399122\n",
      "phase_2/088_Anomaly_4200.csv\n",
      "Current Score:  11.868631412399122\n",
      "phase_2/089_Anomaly_2500.csv\n",
      "Current Score:  11.868631412399122\n",
      "phase_2/090_Anomaly_2000.csv\n",
      "Current Score:  11.868631412399122\n",
      "phase_2/091_Anomaly_3500.csv\n",
      "Current Score:  13.454452760185742\n",
      "phase_2/092_Anomaly_4500.csv\n",
      "Current Score:  13.787496269313074\n",
      "phase_2/093_Anomaly_8000.csv\n",
      "Current Score:  13.625558827182486\n",
      "phase_2/094_Anomaly_3500.csv\n",
      "Current Score:  13.607238375703618\n",
      "phase_2/095_Anomaly_3500.csv\n",
      "Current Score:  13.458113030389018\n",
      "phase_2/096_Anomaly_3500.csv\n",
      "Current Score:  13.32694008250984\n",
      "phase_2/097_Anomaly_2700.csv\n",
      "Current Score:  13.18024622136566\n",
      "phase_2/098_Anomaly_1666.csv\n",
      "Current Score:  13.246497453826677\n",
      "phase_2/099_Anomaly_3333.csv\n",
      "Current Score:  13.726726805114875\n",
      "phase_2/100_Anomaly_3666.csv\n",
      "Current Score:  13.726726805114875\n",
      "phase_2/101_Anomaly_3083.csv\n",
      "Current Score:  13.577720165298727\n",
      "phase_2/102_Anomaly_3900.csv\n",
      "Current Score:  13.431723174274007\n",
      "phase_2/103_Anomaly_3700.csv\n",
      "Current Score:  13.291226119228538\n",
      "phase_2/104_Anomaly_1300.csv\n",
      "Current Score:  13.716024358221182\n",
      "phase_2/105_Anomaly_3511.csv\n",
      "Current Score:  13.685039155186796\n",
      "phase_2/106_Anomaly_4000.csv\n",
      "Current Score:  13.544054274240768\n",
      "phase_2/107_Anomaly_1333.csv\n",
      "Current Score:  13.544054274240768\n",
      "phase_2/108_Anomaly_2526.csv\n",
      "Current Score:  13.544054274240768\n",
      "phase_2/109_Anomaly_5000.csv\n",
      "Current Score:  13.410840765674866\n",
      "phase_2/110_Anomaly_1578.csv\n",
      "Current Score:  13.410840765674866\n",
      "phase_2/111_Anomaly_3684.csv\n",
      "Current Score:  13.353675498243211\n",
      "phase_2/112_Anomaly_3000.csv\n",
      "Current Score:  13.220585670635081\n",
      "phase_2/113_Anomaly_2500.csv\n",
      "Current Score:  13.095396412393498\n",
      "phase_2/114_Anomaly_4000.csv\n",
      "Current Score:  13.095396412393498\n",
      "phase_2/115_Anomaly_4166.csv\n",
      "Current Score:  13.247087636140305\n",
      "phase_2/116_Anomaly_1666.csv\n",
      "Current Score:  13.249363304541678\n",
      "phase_2/117_Anomaly_2602.csv\n",
      "Current Score:  13.161825720319687\n",
      "phase_2/118_Anomaly_3103.csv\n",
      "Current Score:  13.049681348380131\n",
      "phase_2/119_Anomaly_6282.csv\n",
      "Current Score:  12.951975765482876\n",
      "phase_2/120_Anomaly_1282.csv\n",
      "Current Score:  12.951975765482876\n",
      "phase_2/121_Anomaly_3283.csv\n",
      "Current Score:  12.951975765482876\n",
      "phase_2/122_Anomaly_4456.csv\n",
      "Current Score:  12.951975765482876\n",
      "phase_2/123_Anomaly_1179.csv\n",
      "Current Score:  12.951975765482876\n",
      "phase_2/124_Anomaly_1283.csv\n",
      "Current Score:  12.951975765482876\n",
      "phase_2/125_Anomaly_1417.csv\n",
      "Current Score:  12.951975765482876\n",
      "phase_2/126_Anomaly_1490.csv\n",
      "Current Score:  13.075432531328667\n",
      "phase_2/127_Anomaly_1572.csv\n",
      "Current Score:  13.075432531328667\n",
      "phase_2/128_Anomaly_2672.csv\n",
      "Current Score:  13.075432531328667\n",
      "phase_2/129_Anomaly_4117.csv\n",
      "Current Score:  13.210999514063278\n",
      "phase_2/130_Anomaly_4006.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Score:  13.210999514063278\n",
      "phase_2/131_Anomaly_4274.csv\n",
      "Current Score:  13.30048495228932\n",
      "phase_2/132_Anomaly_5059.csv\n",
      "Current Score:  13.30048495228932\n",
      "phase_2/133_Anomaly_2246.csv\n",
      "Current Score:  13.183618775263525\n",
      "phase_2/134_Anomaly_2272.csv\n",
      "Current Score:  13.183618775263525\n",
      "phase_2/135_Anomaly_3272.csv\n",
      "Current Score:  13.523297264085322\n",
      "phase_2/136_Anomaly_3872.csv\n",
      "Current Score:  13.40369822715782\n",
      "phase_2/137_Anomaly_1752.csv\n",
      "Current Score:  13.40369822715782\n",
      "phase_2/138_Anomaly_1752.csv\n",
      "Current Score:  13.79331643360382\n",
      "phase_2/139_Anomaly_2101.csv\n",
      "Current Score:  14.081063580923697\n",
      "phase_2/140_Anomaly_2101.csv\n",
      "Current Score:  14.216059275398063\n",
      "phase_2/141_Anomaly_2101.csv\n",
      "Current Score:  14.152762524604087\n",
      "phase_2/142_Anomaly_2145.csv\n",
      "Current Score:  14.197610708154478\n",
      "phase_2/143_Anomaly_2145.csv\n",
      "Current Score:  14.366287306181663\n",
      "phase_2/144_Anomaly_2367.csv\n",
      "Current Score:  14.245894789628972\n",
      "phase_2/145_Anomaly_2135.csv\n",
      "Current Score:  14.453434501916277\n",
      "phase_2/146_Anomaly_2667.csv\n",
      "Current Score:  14.334343954469611\n",
      "phase_2/147_Anomaly_2777.csv\n",
      "Current Score:  14.334343954469611\n",
      "phase_2/148_Anomaly_3571.csv\n",
      "Current Score:  14.334343954469611\n",
      "phase_2/149_Anomaly_4000.csv\n",
      "Current Score:  14.334343954469611\n",
      "phase_2/150_Anomaly_3333.csv\n",
      "Current Score:  14.334343954469611\n",
      "\tTotal score: 11.563037456605485\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#trial file to see what sticks. not much so far tbh.\n",
    "\n",
    "locations = pd.read_csv(\"phase_2/labels.csv\")\n",
    "locations.set_index(\"Name\", inplace=True)\n",
    "anomalie_files = \"phase_2\"\n",
    "\n",
    "total_score = 0\n",
    "predictions = []\n",
    "ids = []\n",
    "i = 1\n",
    "\n",
    "# Distance-based anomaly scores\n",
    "# Using a k-NN classifier\n",
    "def distance_based_score(X, test_start):\n",
    "    clf = KNeighborsClassifier(n_neighbors=5)    \n",
    "    clf.fit(X, np.ones(len(X)))\n",
    "    dists, _ = clf.kneighbors(X[test_start:], return_distance=True)        \n",
    "    \n",
    "    score = np.zeros(len(X))\n",
    "    score[test_start:] = dists[:,-1]\n",
    "    predicted = test_start + np.argmax(score[test_start:])    \n",
    "    peaks, _ = sp.signal.find_peaks(score, distance=50)\n",
    "    confidence = np.max(score[peaks])/np.max(score[peaks][score[peaks] != np.max(score[peaks])])\n",
    "    return score, predicted, confidence\n",
    "        \n",
    "    \n",
    "# Use a classification approach to detect anaomalies\n",
    "def classifcation_based_scores(X, test_start):   \n",
    "    clf = LocalOutlierFactor(n_neighbors=5, metric='l2', n_jobs=-1)\n",
    "    clf.fit_predict(X)    \n",
    "    score = clf.negative_outlier_factor_\n",
    "    \n",
    "    #clf = IsolationForest().fit(X)\n",
    "    #score = clf.score_samples(X)\n",
    "    \n",
    "    #clf = OneClassSVM(nu = 0.01).fit(X)\n",
    "    #score = clf.score_samples(X)\n",
    "    predicted = test_start + np.argmin(score[test_start:])    \n",
    "    peaks, _ = sp.signal.find_peaks(np.negative(score), distance=50)\n",
    "    confidence = np.min(score[peaks])/np.min(score[peaks][score[peaks] != np.min(score[peaks])])\n",
    "    return score, predicted, confidence\n",
    "\n",
    "# Use a regression-based approach to detect anaomalies\n",
    "def regression_based_scores(X, test_start):\n",
    "    score = np.zeros(len(X))\n",
    "    transform = PolynomialFeatures(degree=3)\n",
    "    \n",
    "    # generate polynomial features\n",
    "    XX = transform.fit_transform(X)\n",
    "\n",
    "    for i, window in enumerate(XX[test_start:]):        \n",
    "        x = np.arange(len(window)).reshape(-1, 1)\n",
    "        y = window.reshape(-1, 1)\n",
    "        \n",
    "        # train polynomial regression        \n",
    "        clf = Ridge(normalize=True).fit(x, y)\n",
    "        pred = clf.predict(x)        \n",
    "        \n",
    "        # check error in regression\n",
    "        score[test_start+i] = np.sum(np.abs(pred - y))\n",
    "        \n",
    "        predicted = test_start + np.argmax(score[test_start:])        \n",
    "    return score, predicted\n",
    "        \n",
    "        \n",
    "        \n",
    "# Use a forecasting-based approach to detect anaomalies\n",
    "def forecasting_based_scores(X, test_start):\n",
    "    score = np.zeros(len(X))\n",
    "    transform = PolynomialFeatures(degree=2)\n",
    "    \n",
    "    # generate polynomial features\n",
    "    XX = transform.fit_transform(X)\n",
    "\n",
    "    # learn to predict last value        \n",
    "    # train polynomial regression        \n",
    "    xs = XX[:, :-1]\n",
    "    ys = XX[:, -1] # predict the last value\n",
    "    clf = Ridge(normalize=True).fit(xs, ys)\n",
    "    \n",
    "    # check error in predicting last value\n",
    "    pred = clf.predict(xs)\n",
    "    score = np.abs(pred - ys)\n",
    "        \n",
    "    predicted = test_start + np.argmax(score[test_start:])        \n",
    "    peaks, _ = sp.signal.find_peaks(score, distance=50)\n",
    "    confidence = np.max(score[peaks])/np.max(score[peaks][score[peaks] != np.max(score[peaks])])\n",
    "    return score, predicted, confidence\n",
    "\n",
    "for file in np.sort(fnmatch.filter(os.listdir(anomalie_files), \"*.csv\")):\n",
    "    if \"Anomaly\" in str(file):\n",
    "        file_name = file.split('.')[0]\n",
    "        name, test_start, data, anomaly = read_series(anomalie_files, file, locations)\n",
    "\n",
    "        periods = find_dominant_window_sizes(data[:test_start])\n",
    "        window_size = np.int32(periods[0] / 4)\n",
    "        X = sliding_window(data, window_size)\n",
    "\n",
    "        #score_dist, predicted_dist, confidence_dist = distance_based_score(X, test_start)\n",
    "        score_class, predicted_class, confidence_class = classifcation_based_scores(X, test_start)\n",
    "        #score, predicted = regression_based_scores(X, test_start)        \n",
    "        #score_fore, predicted_fore, confidence_fore = forecasting_based_scores(X, test_start)\n",
    "        #if (confidence_dist>confidence_class and confidence_dist>confidence_fore):\n",
    "        #    score = score_dist\n",
    "        #    predicted = predicted_dist\n",
    "        #elif confidence_class > confidence_fore:\n",
    "        score = score_class\n",
    "        predicted = predicted_class\n",
    "        #else:\n",
    "        #    score = score_fore\n",
    "        #    predicted = predicted_fore\n",
    "        \n",
    "        predictions.append(predicted)\n",
    "        ids.append(file_name)\n",
    "        \n",
    "        score[:test_start] = np.NaN\n",
    "\n",
    "        # Visualize the predicted anomaly\n",
    "        #visualize_with_anomaly_score(\n",
    "        #     data, score, test_start, predicted, anomaly, name)\n",
    "\n",
    "        if (anomaly > -1):\n",
    "            total_score += abs(anomaly - predicted) / (anomaly)        \n",
    "            i = i+1\n",
    "            \n",
    "        print(\"Current Score: \", (total_score / i) * 100)\n",
    "\n",
    "        \n",
    "print(\"\\tTotal score:\", (total_score / len(locations)) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c22512c",
   "metadata": {},
   "source": [
    "# Submit your solution to Kaggle\n",
    "\n",
    "<div class=\"alert alert-success alertsuccess\" style=\"margin-top: 20px\">\n",
    "Create a submission named `submission.csv` using your model and upload it to kaggle:\n",
    "\n",
    "- Phase 1: https://www.kaggle.com/c/time-series-anomaly-detection\n",
    "- Phase 2: https://www.kaggle.com/competitions/time-series-anomaly-detection-phase-2\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba3f23b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PREDICTED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001_Anomaly_5000</td>\n",
       "      <td>10134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002_Anomaly_4375</td>\n",
       "      <td>8382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003_Anomaly_4375</td>\n",
       "      <td>8387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004_Anomaly_2500</td>\n",
       "      <td>5571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005_Anomaly_4000</td>\n",
       "      <td>5389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>146_Anomaly_2667</td>\n",
       "      <td>9196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>147_Anomaly_2777</td>\n",
       "      <td>6216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>148_Anomaly_3571</td>\n",
       "      <td>6732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>149_Anomaly_4000</td>\n",
       "      <td>6812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>150_Anomaly_3333</td>\n",
       "      <td>6376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID  PREDICTED\n",
       "0    001_Anomaly_5000      10134\n",
       "1    002_Anomaly_4375       8382\n",
       "2    003_Anomaly_4375       8387\n",
       "3    004_Anomaly_2500       5571\n",
       "4    005_Anomaly_4000       5389\n",
       "..                ...        ...\n",
       "145  146_Anomaly_2667       9196\n",
       "146  147_Anomaly_2777       6216\n",
       "147  148_Anomaly_3571       6732\n",
       "148  149_Anomaly_4000       6812\n",
       "149  150_Anomaly_3333       6376\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a submission\n",
    "submission = pd.DataFrame({'ID': ids,'PREDICTED': predictions})\n",
    "\n",
    "#Visualize the first 5 rows\n",
    "display(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba05f9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file: baseline_submission_phase_2.csv\n"
     ]
    }
   ],
   "source": [
    "filename = 'baseline_submission_phase_2.csv'\n",
    "submission.to_csv(filename,index=False)\n",
    "print('Saved file: ' + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4fd534",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
